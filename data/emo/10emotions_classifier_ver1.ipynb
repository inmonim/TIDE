{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/inmo/tide/data/emo/.cache/kobert_v1.zip\n",
      "using cached model. /home/inmo/tide/data/emo/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module): ## 클래스를 상속\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=10,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512  # 텍스트 데이터 최대 길이\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './models/'\n",
    "model = torch.load(PATH + '10emotions_model_1.pt', map_location='cpu')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n",
    "model.load_state_dict(torch.load(PATH + '10emotions_model_state_dict_1.pt', map_location='cpu'))  # state_dict를 불러 온 후, 모델에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/inmo/tide/data/emo/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_list = ['분노', '악의', '슬픔', '절망', '당황', '불안', '열등', '상처', '사랑', '편안']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=2)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for (token_ids, valid_length, segment_ids, label) in test_dataloader:\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        # for i, e in zip(out[0], emotion_list):\n",
    "        #     print(f'{e}: {round(float(i),4)}')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7345,  1.5997,  0.0278,  0.0355,  0.9027, -0.7806, -0.0891,  2.1257,\n",
       "         -2.5588, -2.4621]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가사집 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52441</td>\n",
       "      <td>너에게로 또 다시</td>\n",
       "      <td>['발라드']</td>\n",
       "      <td>그 얼마나 오랜 시간을\\n 짙은 어둠에서 서성거렸나\\n 내 마음을 닫아 둔채로\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53060</td>\n",
       "      <td>솔아 솔아 푸르른 솔아</td>\n",
       "      <td>['포크/블루스']</td>\n",
       "      <td>거센 바람이 불어와서 \\n 어머님의 눈물이 \\n 가슴속에 사무쳐 우는 \\n 갈라진 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1017150</td>\n",
       "      <td>그 아픔까지 사랑한거야</td>\n",
       "      <td>['발라드']</td>\n",
       "      <td>너를 처음 만난 날 소리없이\\n 밤새 눈은 내리고\\n 끝도 없이 찾아드는 기다림\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53018</td>\n",
       "      <td>향기로운 추억 (응답하라 1988 삽입곡)</td>\n",
       "      <td>['발라드']</td>\n",
       "      <td>한줌 젖은 바람은 \\n 이젠 희미해진 옛 추억 \\n 어느 거리로 \\n 날 데리고 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1859404</td>\n",
       "      <td>잊지 말아요</td>\n",
       "      <td>['성인가요/트로트']</td>\n",
       "      <td>이젠 모두 지나버린 일이야 \\n 사랑했던 그 추억 마저도 \\n 하지만 멀리서 \\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id                    title         genre  \\\n",
       "0    52441                너에게로 또 다시       ['발라드']   \n",
       "1    53060             솔아 솔아 푸르른 솔아    ['포크/블루스']   \n",
       "2  1017150             그 아픔까지 사랑한거야       ['발라드']   \n",
       "3    53018  향기로운 추억 (응답하라 1988 삽입곡)       ['발라드']   \n",
       "4  1859404                   잊지 말아요  ['성인가요/트로트']   \n",
       "\n",
       "                                              lyrics  \n",
       "0  그 얼마나 오랜 시간을\\n 짙은 어둠에서 서성거렸나\\n 내 마음을 닫아 둔채로\\n ...  \n",
       "1  거센 바람이 불어와서 \\n 어머님의 눈물이 \\n 가슴속에 사무쳐 우는 \\n 갈라진 ...  \n",
       "2  너를 처음 만난 날 소리없이\\n 밤새 눈은 내리고\\n 끝도 없이 찾아드는 기다림\\n...  \n",
       "3  한줌 젖은 바람은 \\n 이젠 희미해진 옛 추억 \\n 어느 거리로 \\n 날 데리고 가...  \n",
       "4  이젠 모두 지나버린 일이야 \\n 사랑했던 그 추억 마저도 \\n 하지만 멀리서 \\n ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt, Kkma\n",
    "\n",
    "lyrics_df = pd.read_csv('../song/song_data/learn_song_lyrics.csv', index_col=0)\n",
    "lyrics_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장별 리스트 및 한 줄 가사 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518,\n",
       " '소란했던 오늘의 하루가 너와 함께 고요해 작은 입술을 열어 우리의 밤을 노래해 넌 내가 본 가장 아름다운 별 날 꿈꾸게 해 널 위해 태어난 꿈의 조각은 어제보다 널 사랑하게 해 그게 얼마나 날 설레게 하고 널 원하게 만드는지 수많은 시간을 지나 네 품에 가만히 안겨 너에게 잠겨 눈을 감아 이 순간을 담아 행복이라고 예쁘게 적어본다 맞닿은 두 볼에 피어난 미소가 서로의 맘을 비추고 넌 내가 본 가장 눈부신 바다 날 숨 쉬게 해 널 위해 태어난 꿈의 조각은 어제보다 널 사랑하게 해 그게 얼마나 날 설레게 하고 널 원하게 만드는지 수많은 시간을 지나 네 품에 가만히 안겨 너에게 잠겨 눈을 감아 이 순간을 담아 행복이라고 예쁘게 적어본다 나의 어린 날들은 너로 기억될 거야 말로는 다 할 수 없는 커다란 이 맘을 모두 줄게 너라는 이유 그 하나만으로 마음이 말하는 세상으로 빛나는 오늘 함께 하는 우리 모든 게 선물인걸 영원할 순간이 지금 내 앞에 둘만의 특별한 여행을 떠나 너를 안아 사랑을 담아 행복이라고 예쁘게 적어본다 ')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = '마음이 말하는'\n",
    "\n",
    "lyrics = lyrics_df[lyrics_df.title.str.contains(title)].head(1).lyrics.item()\n",
    "lyrics_list = [l for l in lyrics.split(' \\\\n ') if l != '']\n",
    "lyrics = lyrics.replace('\\\\n', '').replace('  ',' ')\n",
    "\n",
    "len(lyrics), lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>3910821</td>\n",
       "      <td>바람기억</td>\n",
       "      <td>['R&amp;B/Soul']</td>\n",
       "      <td>바람 불어와 내 맘 흔들면 \\n 지나간 세월에\\n 두 눈을 감아본다 \\n 나를 스치...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6455</th>\n",
       "      <td>4265960</td>\n",
       "      <td>바람기억</td>\n",
       "      <td>['발라드']</td>\n",
       "      <td>바람 불어와 내 맘 흔들면 \\n 지나간 세월에\\n 두 눈을 감아본다 \\n 나를 스치...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id title         genre  \\\n",
       "5861  3910821  바람기억  ['R&B/Soul']   \n",
       "6455  4265960  바람기억       ['발라드']   \n",
       "\n",
       "                                                 lyrics  \n",
       "5861  바람 불어와 내 맘 흔들면 \\n 지나간 세월에\\n 두 눈을 감아본다 \\n 나를 스치...  \n",
       "6455  바람 불어와 내 맘 흔들면 \\n 지나간 세월에\\n 두 눈을 감아본다 \\n 나를 스치...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df[lyrics_df.title == title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7597, -0.6575, -1.8987,  1.2478, -1.0558, -1.1919,  0.3378, -0.5697,\n",
       "         2.9456,  2.0161], device='cuda:0', grad_fn=<AsStridedBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = predict(lyrics)[0]\n",
    "pre_emo = [0]*10\n",
    "s_len = len(kkma.sentences(lyrics))\n",
    "for lyric in kkma.sentences(lyrics):\n",
    "    emo_tensor = predict(lyric)\n",
    "    for i in range(10):\n",
    "        x = float(emo_tensor[0][i])/s_len\n",
    "        pre_emo[i] += x\n",
    "for i in range(10):\n",
    "    res[i] -= round(pre_emo[i],4)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1841, -0.3606, -1.1250,  2.9031, -2.1992, -1.7852, -0.3203,  0.0435,\n",
       "         3.2826,  1.8496], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(lyrics)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True, False, False, False, False, False,  True],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result > sum(abs(result))/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1839202304"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

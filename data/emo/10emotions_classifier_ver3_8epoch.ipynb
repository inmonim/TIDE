{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/inmo/tide/data/emo/.cache/kobert_v1.zip\n",
      "using cached model. /home/inmo/tide/data/emo/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/inmo/tide/data/emo/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module): ## 클래스를 상속\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=10,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512   # 텍스트 데이터 최대 길이\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './models/'\n",
    "model = torch.load(PATH+'10emotions_model_3_8epoch.pt', map_location='cpu')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n",
    "model.load_state_dict(torch.load(PATH + '10emotions_model_state_dict_3_8epoch.pt', map_location='cpu'))  # state_dict를 불러 온 후, 모델에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_list = ['분노', '악의', '슬픔', '절망', '당황', '불안', '열등', '상처', '사랑', '편안']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, 512, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=2)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for (token_ids, valid_length, segment_ids, label) in test_dataloader:\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        # for i, e in zip(out[0], emotion_list):\n",
    "        #     print(f'{e}: {round(float(i),4)}')\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emotion_list = ['분노', '악의', '슬픔', '절망', '당황', '불안', '열등', '상처', '사랑', '편안']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8537, -0.3090,  0.1065, -1.5159, -1.1381, -1.2867, -1.2769,  0.6009,\n",
       "          4.5829,  1.3934]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('우리의 믿음')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가사집 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52441</td>\n",
       "      <td>너에게로 또 다시</td>\n",
       "      <td>['발라드']</td>\n",
       "      <td>그 얼마나 오랜 시간을\\n 짙은 어둠에서 서성거렸나\\n 내 마음을 닫아 둔채로\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53060</td>\n",
       "      <td>솔아 솔아 푸르른 솔아</td>\n",
       "      <td>['포크/블루스']</td>\n",
       "      <td>거센 바람이 불어와서 \\n 어머님의 눈물이 \\n 가슴속에 사무쳐 우는 \\n 갈라진 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1017150</td>\n",
       "      <td>그 아픔까지 사랑한거야</td>\n",
       "      <td>['발라드']</td>\n",
       "      <td>너를 처음 만난 날 소리없이\\n 밤새 눈은 내리고\\n 끝도 없이 찾아드는 기다림\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53018</td>\n",
       "      <td>향기로운 추억 (응답하라 1988 삽입곡)</td>\n",
       "      <td>['발라드']</td>\n",
       "      <td>한줌 젖은 바람은 \\n 이젠 희미해진 옛 추억 \\n 어느 거리로 \\n 날 데리고 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1859404</td>\n",
       "      <td>잊지 말아요</td>\n",
       "      <td>['성인가요/트로트']</td>\n",
       "      <td>이젠 모두 지나버린 일이야 \\n 사랑했던 그 추억 마저도 \\n 하지만 멀리서 \\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id                    title         genre  \\\n",
       "0    52441                너에게로 또 다시       ['발라드']   \n",
       "1    53060             솔아 솔아 푸르른 솔아    ['포크/블루스']   \n",
       "2  1017150             그 아픔까지 사랑한거야       ['발라드']   \n",
       "3    53018  향기로운 추억 (응답하라 1988 삽입곡)       ['발라드']   \n",
       "4  1859404                   잊지 말아요  ['성인가요/트로트']   \n",
       "\n",
       "                                              lyrics  \n",
       "0  그 얼마나 오랜 시간을\\n 짙은 어둠에서 서성거렸나\\n 내 마음을 닫아 둔채로\\n ...  \n",
       "1  거센 바람이 불어와서 \\n 어머님의 눈물이 \\n 가슴속에 사무쳐 우는 \\n 갈라진 ...  \n",
       "2  너를 처음 만난 날 소리없이\\n 밤새 눈은 내리고\\n 끝도 없이 찾아드는 기다림\\n...  \n",
       "3  한줌 젖은 바람은 \\n 이젠 희미해진 옛 추억 \\n 어느 거리로 \\n 날 데리고 가...  \n",
       "4  이젠 모두 지나버린 일이야 \\n 사랑했던 그 추억 마저도 \\n 하지만 멀리서 \\n ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt, Kkma\n",
    "\n",
    "lyrics_df = pd.read_csv('../song/song_data/csv/learn_song_lyrics.csv', index_col=0)\n",
    "lyrics_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장별 리스트 및 한 줄 가사 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634,\n",
       " '별빛이 내린 밤 그 풍경 속 너와 나 날 새롭게 하는 따뜻하게 만드는 니 눈빛 니 미소 영원히 담아둘게 너로 가득한 맘 널 닮아가는 나 날 위한 선물 꿈보다 더 아름다운 서로의 품에서 끝 없는 밤을 걷자 나의 모든 날들을 다 주고싶어 내 이 맘을 모두 전하고 싶어 잠들지 못한 푸른 바람들 이렇게 밝게 이 밤을 비춰 너와 작은 일상을 함께 하는게 내 가장 큰 기쁨인걸 넌 알까 내 세상 속에 넌 빛이 되어 지금 모습 그대로 내 곁에만 행복이 짙은 날 어둠이 없는 밤 같은 맘 속에 같은 꿈이 피어난 건 우리의 정해진 운명이 맞닿은거야 나의 모든 날들을 다 주고싶어 내 이 맘을 모두 전하고 싶어 잠들지 못한 푸른 바람들 이렇게 밝게 이 밤을 비춰 너와 작은 일상을 함께 하는게 내 가장 큰 기쁨인걸 넌 알까 내 세상 속에 넌 빛이 되어 지금 모습 그대로 내 곁에만 내게 온 너란 빛이 눈 부셔도 네 앞에서 한 순간도 눈 감지 않아 다가올 시간도 계절의 바람도 널 데려가지 못하게 내가 더 좋은 사람이 되고 싶어 더 아름답게 널 안을 수 있게 잠들지 못한 잠들 수 없는 바람들이 널 부르고 있어 언제까지나 너와 함께 할거야 내 마지막 숨결도 너일거야 내 세상 속에 넌 빛이 되어 지금 모습 그대로 내 곁에만 이렇게 밝게 이 밤을 비춰 ')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = '오늘도 빛나는'\n",
    "\n",
    "lyrics = lyrics_df[lyrics_df.title.str.contains(title)].head(1).lyrics.item()\n",
    "lyrics_list = [l for l in lyrics.split(' \\\\n ') if l != '']\n",
    "lyrics = lyrics.replace('\\\\n', '').replace('  ', ' ')\n",
    "\n",
    "len(lyrics), lyrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석을 통해 각 행마다의 값을 n으로 나누어 누적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = predict(lyrics)[0]\n",
    "pre_emo = [0]*10\n",
    "s_len = len(kkma.sentences(lyrics))\n",
    "for lyric in kkma.sentences(lyrics):\n",
    "    emo_tensor = predict(lyric)\n",
    "    for i in range(10):\n",
    "        x = float(emo_tensor[0][i])/s_len\n",
    "        pre_emo[i] += x\n",
    "for i in range(10):\n",
    "    res[i] -= round(pre_emo[i],4)\n",
    "\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체를 돌려버리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분노 3.6969218254089355\n",
      "악의 1.2098770141601562\n",
      "슬픔 -0.13585776090621948\n",
      "절망 0.11310271173715591\n",
      "당황 0.08569256216287613\n",
      "불안 0.7442466616630554\n",
      "열등 0.7030786275863647\n",
      "상처 -0.04318148270249367\n",
      "사랑 -2.7536795139312744\n",
      "편안 -2.838031053543091\n"
     ]
    }
   ],
   "source": [
    "result = predict(lyrics)[0]\n",
    "for n, e in zip(emotion_list, result):\n",
    "    print(n, float(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가사 분석 결과를 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emo_rank(pre_result):\n",
    "    if pre_result[8] >= math.sqrt(sum(abs(result))/10):\n",
    "        pre_result[8] = max(float(pre_result[8] ** 2), pre_result[8])\n",
    "    if pre_result[9] >= math.sqrt(sum(abs(result))/10):\n",
    "        pre_result[9] = max(float(pre_result[9] ** 2), pre_result[9])\n",
    "        \n",
    "    for i in range(8):\n",
    "        pre_result[i] = (pre_result[i]/5)*4\n",
    "    \n",
    "    mask = sorted(enumerate(pre_result), key=lambda x:x[1], reverse=True)\n",
    "    e = []\n",
    "    tmp = []\n",
    "    for i, x in mask:\n",
    "        if len(e) >= 3:\n",
    "            break\n",
    "        if x > float(sum(abs(result))/len(result)):\n",
    "            e.append(i+1)\n",
    "        elif x >= math.sqrt(abs(sum(result)))/len(result):\n",
    "            tmp.append(i+11)\n",
    "    else:\n",
    "        while len(e) < 3:\n",
    "            if tmp:\n",
    "                e.append(tmp.pop(0))\n",
    "            else:\n",
    "                e.append(0)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719c41485cae41e795021e22d5a63174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m title \u001b[39m=\u001b[39m lyrics_df\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m lyrics \u001b[39m=\u001b[39m lyrics_df\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mlyrics\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m pre_res \u001b[39m=\u001b[39m predict(lyrics)\n\u001b[1;32m      8\u001b[0m e \u001b[39m=\u001b[39m emo_rank(pre_res[\u001b[39m0\u001b[39m])\n\u001b[1;32m      9\u001b[0m emo_rank_df\u001b[39m.\u001b[39mloc[i, :] \u001b[39m=\u001b[39m [song_id, title, e[\u001b[39m0\u001b[39m], e[\u001b[39m1\u001b[39m], e[\u001b[39m2\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(predict_sentence)\u001b[0m\n\u001b[1;32m     15\u001b[0m valid_length\u001b[39m=\u001b[39m valid_length\n\u001b[1;32m     16\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m out \u001b[39m=\u001b[39m model(token_ids, valid_length, segment_ids)\n\u001b[1;32m     20\u001b[0m \u001b[39m# for i, e in zip(out[0], emotion_list):\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m#     print(f'{e}: {round(float(i),4)}')\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mBERTClassifier.forward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, token_ids, valid_length, segment_ids):\n\u001b[1;32m     23\u001b[0m     attention_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen_attention_mask(token_ids, valid_length)\n\u001b[0;32m---> 25\u001b[0m     _, pooler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(input_ids \u001b[39m=\u001b[39;49m token_ids, token_type_ids \u001b[39m=\u001b[39;49m segment_ids\u001b[39m.\u001b[39;49mlong(), attention_mask \u001b[39m=\u001b[39;49m attention_mask\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mto(token_ids\u001b[39m.\u001b[39;49mdevice))\n\u001b[1;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdr_rate:\n\u001b[1;32m     27\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooler)\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:991\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    982\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    984\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    985\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    986\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    989\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    990\u001b[0m )\n\u001b[0;32m--> 991\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    992\u001b[0m     embedding_output,\n\u001b[1;32m    993\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    994\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    995\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    996\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    997\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    998\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    999\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1000\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1001\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1002\u001b[0m )\n\u001b[1;32m   1003\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1004\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    573\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    574\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    575\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[1;32m    581\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    583\u001b[0m         hidden_states,\n\u001b[1;32m    584\u001b[0m         attention_mask,\n\u001b[1;32m    585\u001b[0m         layer_head_mask,\n\u001b[1;32m    586\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    587\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    588\u001b[0m         past_key_value,\n\u001b[1;32m    589\u001b[0m         output_attentions,\n\u001b[1;32m    590\u001b[0m     )\n\u001b[1;32m    592\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:470\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    459\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    460\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m ):\n\u001b[1;32m    468\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    471\u001b[0m         hidden_states,\n\u001b[1;32m    472\u001b[0m         attention_mask,\n\u001b[1;32m    473\u001b[0m         head_mask,\n\u001b[1;32m    474\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    475\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    476\u001b[0m     )\n\u001b[1;32m    477\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    479\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:401\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    392\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    393\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m ):\n\u001b[0;32m--> 401\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    402\u001b[0m         hidden_states,\n\u001b[1;32m    403\u001b[0m         attention_mask,\n\u001b[1;32m    404\u001b[0m         head_mask,\n\u001b[1;32m    405\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    406\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    407\u001b[0m         past_key_value,\n\u001b[1;32m    408\u001b[0m         output_attentions,\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    411\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:290\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey(hidden_states))\n\u001b[0;32m--> 290\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue(hidden_states))\n\u001b[1;32m    292\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder:\n\u001b[1;32m    295\u001b[0m     \u001b[39m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/functional.py:1848\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   1847\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> 1848\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emo_rank_df = pd.DataFrame(columns=['song_id', 'title', '1emo','2emo','3emo'])\n",
    "\n",
    "for i in tqdm(range(len(lyrics_df))):\n",
    "    song_id = lyrics_df.loc[i, 'song_id']\n",
    "    title = lyrics_df.loc[i, 'title']\n",
    "    lyrics = lyrics_df.loc[i, 'lyrics'].replace('\\\\n', ' ')\n",
    "    pre_res = predict(lyrics)\n",
    "    e = emo_rank(pre_res[0])\n",
    "    emo_rank_df.loc[i, :] = [song_id, title, e[0], e[1], e[2]]\n",
    "\n",
    "emo_rank_df.to_csv('../song/lyrics_emotion_ver3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '오늘은 너무 행복한 날이었어!'\n",
    "\n",
    "r = predict(text)\n",
    "rr = emo_rank(r[0])\n",
    "\n",
    "print(r)\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_rank_df[emo_rank_df.loc[:, 'title']=='좋은 날']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[(result > math.sqrt(sum(abs(result))/10)) & (result < sum(abs(result))/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result > math.sqrt(abs(sum(result))/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result > sum(abs(result))/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

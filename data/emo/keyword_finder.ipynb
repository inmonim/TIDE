{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/inmo/tide_pjt/data/emo/.cache/kobert_v1.zip\n",
      "using cached model. /home/inmo/tide_pjt/data/emo/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = pd.read_csv('../song/song_data/learn_song_lyrics.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'너없는 지금도 눈부신 하늘과  눈부시게 웃는 사람들  나의 헤어짐을 모르는 세상은  슬프도록 그대로인데  시간마저 데려가지 못하게  나만은 널 보내지 못했나봐  가시처럼 깊게 박힌 기억은  아파도 아픈 줄 모르고  그대 기억이 지난 사랑이  내 안을 파고드는 가시가 되어  제발 가라고 아주 가라고  애써도 나를 괴롭히는데  아픈 만큼 너를 잊게 된다면  차라리 앓고 나면 그만인데  가시처럼 깊게 박힌 기억은  아파도 아픈 줄 모르고  그대 기억이 지난 사랑이  내 안을 파고드는 가시가 되어  제발 가라고 아주 가라고  애써도 나를 괴롭히는데  너무 사랑했던 나를  그게 두려웠던 나를  미치도록 너를 그리워했던  날 이제는 놓아줘  보이지 않아 내안에 숨어  잊으려하면 할 수록 더 아파와  제발 가라고 아주 가라고  애써도 나를 괴롭히는데 '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = lyrics_df[lyrics_df.loc[:,'title'] == '가시'].head(1).lyrics.item()\n",
    "text = text.replace('\\\\n', '')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(bertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('잊으려하면 수록 아파와', 0.7477),\n",
       " ('잊으려하면 수록 아파와 제발', 0.7345),\n",
       " ('숨어 잊으려하면 수록 아파와', 0.729),\n",
       " ('내안에 숨어 잊으려하면 수록 아파와', 0.7245),\n",
       " ('숨어 잊으려하면 수록 아파와 제발', 0.7224)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 5), stop_words=None, top_n=2)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e513ceedbb9841d8b85342e536034f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m title \u001b[39m=\u001b[39m lyrics_df\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m text \u001b[39m=\u001b[39m lyrics_df\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mlyrics\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m kw \u001b[39m=\u001b[39m kw_model\u001b[39m.\u001b[39;49mextract_keywords(text, keyphrase_ngram_range\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m, \u001b[39m5\u001b[39;49m), stop_words\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, top_n\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m lyrics_keyword\u001b[39m.\u001b[39mloc[i, :] \u001b[39m=\u001b[39m [song_id, title, kw]\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/keybert/_model.py:176\u001b[0m, in \u001b[0;36mKeyBERT.extract_keywords\u001b[0;34m(self, docs, candidates, keyphrase_ngram_range, stop_words, top_n, min_df, use_maxsum, use_mmr, diversity, nr_candidates, vectorizer, highlight, seed_keywords, doc_embeddings, word_embeddings)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m# Extract embeddings\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m doc_embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     doc_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49membed(docs)\n\u001b[1;32m    177\u001b[0m \u001b[39mif\u001b[39;00m word_embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     word_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39membed(words)\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/keybert/backend/_sentencetransformers.py:62\u001b[0m, in \u001b[0;36mSentenceTransformerBackend.embed\u001b[0;34m(self, documents, verbose)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed\u001b[39m(\u001b[39mself\u001b[39m, documents: List[\u001b[39mstr\u001b[39m], verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     51\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Embed a list of n documents/words into an n-dimensional\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49mencode(documents, show_progress_bar\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tide/lib/python3.9/site-packages/sentence_transformers/models/Pooling.py:101\u001b[0m, in \u001b[0;36mPooling.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooling_mode_mean_sqrt_len_tokens:\n\u001b[1;32m     99\u001b[0m         output_vectors\u001b[39m.\u001b[39mappend(sum_embeddings \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39msqrt(sum_mask))\n\u001b[0;32m--> 101\u001b[0m output_vector \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(output_vectors, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    102\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39msentence_embedding\u001b[39m\u001b[39m'\u001b[39m: output_vector})\n\u001b[1;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m features\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lyrics_keyword = pd.DataFrame(columns=['song_id', 'title', 'key_sentence'])\n",
    "\n",
    "for i in tqdm(range(len(lyrics_df))):\n",
    "    song_id = lyrics_df.loc[i, 'song_id']\n",
    "    title = lyrics_df.loc[i, 'title']\n",
    "    text = lyrics_df.loc[i, 'lyrics'].replace('\\\\n','')\n",
    "    kw = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 5), stop_words=None, top_n=3)\n",
    "    \n",
    "    lyrics_keyword.loc[i, :] = [song_id, title, kw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_keyword.to_csv('lyrics_keyword.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>kw1</th>\n",
       "      <th>kw2</th>\n",
       "      <th>kw3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>193014</td>\n",
       "      <td>먼 훗날</td>\n",
       "      <td>너를</td>\n",
       "      <td>진정</td>\n",
       "      <td>사랑했다고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>57339</td>\n",
       "      <td>너를 사랑해</td>\n",
       "      <td>너를</td>\n",
       "      <td>사랑해</td>\n",
       "      <td>영원히</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>56880</td>\n",
       "      <td>첫인상</td>\n",
       "      <td>너를</td>\n",
       "      <td>상상하고</td>\n",
       "      <td>있었지만</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>91110</td>\n",
       "      <td>그때는 알겠지</td>\n",
       "      <td>너를</td>\n",
       "      <td>사랑한다는</td>\n",
       "      <td>이유로</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>91435</td>\n",
       "      <td>처음 그 느낌처럼</td>\n",
       "      <td>너를</td>\n",
       "      <td>사랑했었나</td>\n",
       "      <td>이제는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>2135570</td>\n",
       "      <td>벌 받을 거야</td>\n",
       "      <td>너를</td>\n",
       "      <td>너무</td>\n",
       "      <td>사랑해서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>2210968</td>\n",
       "      <td>Love Sick (러브 시크) (Feat. 바비킴)</td>\n",
       "      <td>너를</td>\n",
       "      <td>비워내본다</td>\n",
       "      <td>사랑해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>2210969</td>\n",
       "      <td>Love Cuts (러브 컷츠) (Feat. 은지원)</td>\n",
       "      <td>너를</td>\n",
       "      <td>잊기가</td>\n",
       "      <td>너무</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>2255863</td>\n",
       "      <td>Call me</td>\n",
       "      <td>너를</td>\n",
       "      <td>따르릉</td>\n",
       "      <td>여보세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>2343748</td>\n",
       "      <td>기다리다 지친다</td>\n",
       "      <td>너를</td>\n",
       "      <td>기다리다</td>\n",
       "      <td>지쳐</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id                          title kw1    kw2    kw3\n",
       "286    193014                           먼 훗날  너를     진정  사랑했다고\n",
       "319     57339                         너를 사랑해  너를    사랑해    영원히\n",
       "330     56880                            첫인상  너를   상상하고   있었지만\n",
       "344     91110                        그때는 알겠지  너를  사랑한다는    이유로\n",
       "349     91435                      처음 그 느낌처럼  너를  사랑했었나    이제는\n",
       "...       ...                            ...  ..    ...    ...\n",
       "4168  2135570                        벌 받을 거야  너를     너무   사랑해서\n",
       "4235  2210968  Love Sick (러브 시크) (Feat. 바비킴)  너를  비워내본다    사랑해\n",
       "4247  2210969  Love Cuts (러브 컷츠) (Feat. 은지원)  너를    잊기가     너무\n",
       "4279  2255863                        Call me  너를    따르릉   여보세요\n",
       "4374  2343748                       기다리다 지친다  너를   기다리다     지쳐\n",
       "\n",
       "[83 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
